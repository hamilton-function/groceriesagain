{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GMapsSIGSPATIAL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U googlemaps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSWaHWUzb_Xr",
        "outputId": "1e7e4f4f-88d0-4ee9-95f6-1f848f8f40ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googlemaps\n",
            "  Downloading googlemaps-4.6.0.tar.gz (31 kB)\n",
            "Requirement already satisfied: requests<3.0,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from googlemaps) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.20.0->googlemaps) (1.24.3)\n",
            "Building wheels for collected packages: googlemaps\n",
            "  Building wheel for googlemaps (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googlemaps: filename=googlemaps-4.6.0-py3-none-any.whl size=38554 sha256=cbefcf84400fcaf022c3b4f974cf7ea92e2ac458ee28d5cdc6a6a2f8c0e82804\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/db/c0/6d958585fa97b20e250bf437acf7e6e715b4809c2dd4e55367\n",
            "Successfully built googlemaps\n",
            "Installing collected packages: googlemaps\n",
            "Successfully installed googlemaps-4.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QtvGZIeyaX_-"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import googlemaps # pip install googlemaps\n",
        "import pandas as pd # pip install pandas\n",
        "\n",
        "\n",
        "API_KEY = 'INSERT YOUR GOOGLE API KEY HERE'\n",
        "map_client = googlemaps.Client(API_KEY)\n",
        "\n",
        "address = 'INSERT YOUR DESTINATION ADDRESS HERE'\n",
        "geocode = map_client.geocode(address=address)\n",
        "(lat, lng) = map(geocode[0]['geometry']['location'].get, ('lat', 'lng'))\n",
        "\n",
        "\n",
        "search_string = 'INSERT STORE NAME HERE'\n",
        "distance = 8000 #this represents the eps-range of the search query in meters\n",
        "business_list = []\n",
        "\n",
        "response = map_client.places_nearby(\n",
        "    location=(lat, lng),\n",
        "    keyword=search_string,\n",
        "    radius=distance\n",
        ")   \n",
        "\n",
        "business_list.extend(response.get('results'))\n",
        "next_page_token = response.get('next_page_token')\n",
        "\n",
        "while next_page_token:\n",
        "    time.sleep(2)\n",
        "    response = map_client.places_nearby(\n",
        "        location=(lat, lng),\n",
        "        keyword=search_string,\n",
        "        radius=distance,\n",
        "        page_token=next_page_token\n",
        "    )   \n",
        "    business_list.extend(response.get('results'))\n",
        "    next_page_token = response.get('next_page_token')\n",
        "\n",
        "df = pd.DataFrame(business_list)\n",
        "df['url'] = 'https://www.google.com/maps/place/?q=place_id:' + df['place_id']\n",
        "#df.to_excel('{0}.xlsx'.format(search_string), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Storing data within a dictionary of the following structure:\n",
        "key: place_id\n",
        "value: [lat, lng, dist]\n",
        "'''\n",
        "\n",
        "#convert to dictionary of structure sketched in the preembel of this cell (key:, ...,value:...)\n",
        "def extractPID_Lat_Lon(pdframe):\n",
        "  #init dictionary:\n",
        "  candidate_loc_dic = {}\n",
        "  pdframe = pdframe.reset_index()  # make sure indexes pair with number of rows\n",
        "  for index, row in pdframe.iterrows():\n",
        "    #extract lat, lng\n",
        "    loc_lat = ((row['geometry'])['location'])['lat']\n",
        "    loc_lng = ((row['geometry'])['location'])['lng']\n",
        "    loc_id = row['place_id']\n",
        "    candidate_loc_dic[loc_id] = [loc_lat, loc_lng] \n",
        "  return candidate_loc_dic\n",
        "\n",
        "extracted_dict = extractPID_Lat_Lon(df)\n"
      ],
      "metadata": {
        "id": "YlYNPcniv9Ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "Code originally from: https://stackoverflow.com/questions/58053077/get-distance-from-google-cloud-maps-directions-api\n",
        "\n",
        "also on shortest routes in google maps: https://stackoverflow.com/questions/18574496/google-distance-matrix-json-shortest-path-php\n",
        "\n",
        "Input: takes two coordinates/locations\n",
        "Output: the shortest path/distance from all possible routes between the two coordinates proposed by google\n",
        "'''\n",
        "\n",
        "# Import libraries\n",
        "import googlemaps\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_shortest_distance(coordStart, coordDestination):\n",
        "  #transform format of coordinates (lat, lng) to 'lat,long'\n",
        "  coords_0 = str(coordStart[0])+','+str(coordStart[1])\n",
        "  coords_1 = str(coordDestination[0])+','+str(coordDestination[1])\n",
        "\n",
        "  # Request directions\n",
        "  now = datetime.now()\n",
        "  directions_result = map_client.directions(coords_0, coords_1, mode=\"driving\", departure_time=now, alternatives = True)\n",
        "\n",
        "  #stores distances of all paths from start to destination\n",
        "  distances_array = []\n",
        "\n",
        "  for path in directions_result:\n",
        "    # Get distance\n",
        "    distance = 0\n",
        "    legs = path.get(\"legs\")\n",
        "    for leg in legs:\n",
        "      distance = (distance + leg.get(\"distance\").get(\"value\"))/1000.0\n",
        "    distances_array.append(distance)\n",
        "  mindist = np.min(distances_array)\n",
        "  #print(distances_array)\n",
        "  return mindist"
      ],
      "metadata": {
        "id": "m1KcQF29uqRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "routine takes the dictionary with place_id as key and appends the shortest distance from a starting point to the destination in its value array: [lat, lng, dist]\n",
        "'''\n",
        "\n",
        "def append_shortest_distances_to_querydict(querydict, startpos):\n",
        "  for key in querydict.keys():\n",
        "    destpos = ((querydict[key])[0],(querydict[key])[1])\n",
        "    shortestdist = get_shortest_distance(startpos, destpos)\n",
        "    querydict[key].append(shortestdist)\n",
        "\n"
      ],
      "metadata": {
        "id": "Wuv11gfBLK82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "routine computes the duration of the /fastest/ path and returns the duration in minutes\n",
        "\n",
        "Code originally from: https://stackoverflow.com/questions/14635926/google-maps-api-travel-time-with-current-traffic\n",
        "\n",
        "\n",
        "Input: takes two coordinates/locations\n",
        "Output: the fastest path from all possible routes between the two coordinates proposed by google\n",
        "'''\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import googlemaps\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_fastest_path_duration(coordStart, coordDestination):\n",
        "  #transform format of coordinates (lat, lng) to 'lat,long'\n",
        "  coords_0 = str(coordStart[0])+','+str(coordStart[1])\n",
        "  coords_1 = str(coordDestination[0])+','+str(coordDestination[1])\n",
        "\n",
        "  # Request directions\n",
        "  now = datetime.now()\n",
        "  directions_result = map_client.directions(coords_0, coords_1, mode=\"driving\", departure_time=now, alternatives = True)\n",
        "\n",
        "  #stores durations of all paths from start to destination\n",
        "  durations_array = []\n",
        "\n",
        "  for path in directions_result:\n",
        "    # Get distance\n",
        "    duration = 0\n",
        "    legs = path.get(\"legs\")\n",
        "    for leg in legs:\n",
        "      duration = (duration + leg.get(\"duration_in_traffic\").get(\"value\"))/60.0\n",
        "    durations_array.append(duration)\n",
        "  mindur = np.min(durations_array)\n",
        "  #print(durations_array)\n",
        "  return mindur\n"
      ],
      "metadata": {
        "id": "ekpH8u134uLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "routine takes the dictionary with place_id as key and appends the lowest driving duration from a starting point to the destination in its value array: [lat, lng, dur]\n",
        "'''\n",
        "\n",
        "def append_minduration_path_to_querydict(querydict, startpos):\n",
        "  for key in querydict.keys():\n",
        "    destpos = ((querydict[key])[0],(querydict[key])[1])\n",
        "    mindurdist = get_fastest_path_duration(startpos, destpos)\n",
        "    querydict[key].append(mindurdist)\n",
        "\n"
      ],
      "metadata": {
        "id": "qXoBxwKTVOp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade git+https://github.com/m-wrzr/populartimes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0BA7yUAYk1c",
        "outputId": "2bfc53e4-6cd2-4329-9e11-d4fe788fcf5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/m-wrzr/populartimes\n",
            "  Cloning https://github.com/m-wrzr/populartimes to /tmp/pip-req-build-z5xknpfs\n",
            "  Running command git clone -q https://github.com/m-wrzr/populartimes /tmp/pip-req-build-z5xknpfs\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.7/dist-packages (from populartimes==2.0) (2.23.0)\n",
            "Collecting geopy<3,>=2\n",
            "  Downloading geopy-2.2.0-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 26.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<2,>=1.21 in /usr/local/lib/python3.7/dist-packages (from populartimes==2.0) (1.24.3)\n",
            "Requirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy<3,>=2->populartimes==2.0) (1.52)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->populartimes==2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->populartimes==2.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>2->populartimes==2.0) (3.0.4)\n",
            "Building wheels for collected packages: populartimes\n",
            "  Building wheel for populartimes (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for populartimes: filename=populartimes-2.0-py3-none-any.whl size=13551 sha256=eb8672da3ea8f5a374dc2cc8c974b43277bcb29687e0de1a6a50996d4e9bbdbe\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vw9dnetj/wheels/94/ce/3d/b7e3c37d5c3375d6435ff071b662d5f0b772607154c41daf9b\n",
            "Successfully built populartimes\n",
            "Installing collected packages: geopy, populartimes\n",
            "  Attempting uninstall: geopy\n",
            "    Found existing installation: geopy 1.17.0\n",
            "    Uninstalling geopy-1.17.0:\n",
            "      Successfully uninstalled geopy-1.17.0\n",
            "Successfully installed geopy-2.2.0 populartimes-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "routine takes a place_id\n",
        "it returns the current popularity \"current_popularity\" -> normalize by dividing the popular time value (i.e. 33) by the mean value on that particular week day (i.e. 28).\n",
        "A value >1 indicates that this place is busier than \"on average\" at those week days, while a value close to 0 means that this place is barely visited right now contrary to the \"average\" busy time\n",
        "\n",
        "get_id(api_key, place_id)\n",
        "    retrieves the CURRENT popularity for a given place\n",
        "    :param api_key:\n",
        "    :param place_id:\n",
        "    :return: see readme\n",
        "'''\n",
        "\n",
        "import populartimes\n",
        "#for getting weekday\n",
        "import datetime\n",
        "import numpy\n",
        "\n",
        "\n",
        "def compute_relative_popularTimes(place_id):\n",
        "  #fetch current weekday as string\n",
        "  weekdaymap = {0 : 'Monday', 1 : 'Tuesday', 2 : 'Wednesday', 3 : 'Thursday', 4 : 'Friday', 5 : 'Saturday', 6 : 'Sunday'}\n",
        "  currweekday = weekdaymap[datetime.datetime.today().weekday()]\n",
        "\n",
        "  if('current_popularity' in populartimes.get_id(API_KEY, place_id).keys()):\n",
        "    #current popularity of that place\n",
        "    curr_pop = populartimes.get_id(API_KEY, place_id)['current_popularity']\n",
        "    #average popularity on that day for that place\n",
        "    day_avg_pop = []\n",
        "    #fetch the array with the data of popular times for one location\n",
        "    populartimesarray = populartimes.get_id(API_KEY, place_id)['populartimes']\n",
        "    if populartimesarray:\n",
        "      for day in populartimesarray:\n",
        "        #fetch the data for the current weekday, returns an array of populartimes over each hour of the current weekday\n",
        "        if day['name'] == currweekday:\n",
        "          day_avg_pop = day['data']\n",
        "\n",
        "    #compute for the current weekday populartimes its average\n",
        "    daily_avg_pop = None\n",
        "    if day_avg_pop:\n",
        "      daily_avg_pop = np.average(day_avg_pop)\n",
        "  \n",
        "    #get current hour\n",
        "    now = datetime.datetime.now()\n",
        "    currhour = now.hour + 1\n",
        "    currhourpop = day_avg_pop[currhour]\n",
        "    #compute relative current popularity by dividing the current popularity by the average popularity of the current day\n",
        "    comp2avg_pop = None\n",
        "    if (daily_avg_pop != None) and (curr_pop != None):\n",
        "      comp2avg_pop = curr_pop / currhourpop\n",
        "\n",
        "    return comp2avg_pop\n",
        "  else:\n",
        "    return numpy.inf\n",
        "  \n"
      ],
      "metadata": {
        "id": "nBv-31A3E6GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "routine takes the dictionary with place_id as key and appends the relative popular time of the day: [lat, lng, dur, relpop]\n",
        "'''\n",
        "\n",
        "def append_relpopularity_to_querydict(querydict):\n",
        "  for key in querydict.keys():\n",
        "    relpop = compute_relative_popularTimes(key)\n",
        "    querydict[key].append(relpop)"
      ],
      "metadata": {
        "id": "W8QvvPE8Y0bi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "initial cell for timeline data analysis\n",
        "data stored in google drive /timelinedata\n",
        "json files for each month over year(s)\n",
        "'''\n",
        "\n",
        "import json\n",
        "from datetime import date\n",
        "import glob\n",
        "\n",
        "#supermarket timeline dictionary\n",
        "timelinedict = {'Aldi' : [],\n",
        "                'Rewe' : [], \n",
        "                'Lidl' : [], \n",
        "                'Edeka' : [], \n",
        "                'Famila' : [], \n",
        "                'real' : [], \n",
        "                'Netto' : [], \n",
        "                'Norma' : [], \n",
        "                'Rossmann' : [], \n",
        "                'dm' : [], \n",
        "                'Kaufland' : [], \n",
        "                'Marktkauf' : [], \n",
        "                'Action' : [], \n",
        "                'Markant' : [], \n",
        "                'Penny' : [], \n",
        "                'V-Markt' : [], \n",
        "                'Hit' : []}\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "store in timeline-dictionary:\n",
        "\n",
        "first access each file, iterate through and fetch per grocery store/supermarket (keys)\n",
        "the confidence (should be 60% or above) then store the timestamp in an array (values).\n",
        "through this we can cover:\n",
        "(1) the overall frequency how often which supermarket was visited\n",
        "(2) the recency, which supermarket was visited how many days ago\n",
        "\n",
        "regarding (1) we cut later on the dictionary based on the top-k most frequently visited supermarkets\n",
        "'''\n",
        "\n",
        "#routine for a single json file in a folder of timeline data\n",
        "\n",
        "def populateTimelineDict(singlejson):\n",
        "  #json files in a folder named timelinedata of the form YEAR_MONTH.json, e.g. 2022_APRIL.json\n",
        "  with open(singlejson, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "  for i in range(len(data['timelineObjects'])):\n",
        "    if 'placeVisit' in data['timelineObjects'][i].keys():\n",
        "\n",
        "      #check if location has a name...\n",
        "      if 'name' in data['timelineObjects'][i]['placeVisit']['location'].keys():\n",
        "\n",
        "        #timelineObjects --> entry index (0,1,2...,n) --> placeVisit --> location --> name\n",
        "        #remark on name: check if name from supermarktlist is partially in the location name, e.g. aldi in list is in aldi kronshagen in timeline name; python substring/contains function\n",
        "        locationname = data['timelineObjects'][i]['placeVisit']['location']['name']\n",
        "\n",
        "        #timelineObjects --> entry index (0,1,2...,n) --> placeVisit --> location --> locationConfidence (should be >=60)\n",
        "        locationconfidence = data['timelineObjects'][i]['placeVisit']['location']['locationConfidence']\n",
        "\n",
        "        #timelineObjects --> entry index (0,1,2...,n) --> placeVisit --> duration --> endTimestamp (capture only YYYY-MM-DD)\n",
        "        lasttimevisited = date.fromisoformat(data['timelineObjects'][i]['placeVisit']['duration']['endTimestamp'][:10])\n",
        "\n",
        "        #check if name of supermarket is at least partially in any key of the timeline dictionary...\n",
        "        for key in timelinedict.keys():\n",
        "          #split locationname by whitespace and take first string, since that contains the supermarket name, make sure that cases don't matter\n",
        "          #by making both, dictionary key and locationname to lowercase\n",
        "          locnameadapted = ((locationname.split())[0]).lower()\n",
        "          keyadapted = key.lower()\n",
        "          if locnameadapted == keyadapted and locationconfidence >= 60:\n",
        "            timelinedict[key].append(lasttimevisited)\n",
        "\n"
      ],
      "metadata": {
        "id": "E-X3GIOI7Gtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Routine to prune timeline dictionary to the top 5 / most frequently visited places\n",
        "'''\n",
        "def pruneTimelineDict(tldict,topk):\n",
        "  #get first all frequencies sorted in descending order\n",
        "  frequencyarray = []\n",
        "  for key in tldict:\n",
        "    freq = len(tldict[key])\n",
        "    frequencyarray.append(freq)\n",
        "  frequencyarray.sort(reverse=True)\n",
        "\n",
        "  #then access at position topk-1 use that value for pruning\n",
        "  pruningthreshold = frequencyarray[topk-1]\n",
        "\n",
        "  #start pruning for all entries in the tldict that have a value array length < pruningthreshold\n",
        "  for key in list(tldict):\n",
        "    if len(tldict[key]) < pruningthreshold:\n",
        "      del tldict[key]\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Function retrieves for -one- supermarket location in a 2 km radius other supermarkets (need to remove the supermarket location (start point) itself)\n",
        "and stores their names in an array\n",
        "'''\n",
        "def getNearbySupermarkets(lat, lng):\n",
        "  search_query = 'supermarket'\n",
        "  distance = 2000 #this represents the eps-range of the search query in meters\n",
        "  business_list = []\n",
        "\n",
        "  response = map_client.places_nearby(\n",
        "      location=(lat, lng),\n",
        "      keyword=search_query,\n",
        "      radius=distance\n",
        "  )   \n",
        "\n",
        "  business_list.extend(response.get('results'))\n",
        "  next_page_token = response.get('next_page_token')\n",
        "\n",
        "  while next_page_token:\n",
        "      time.sleep(2)\n",
        "      response = map_client.places_nearby(\n",
        "          location=(lat, lng),\n",
        "          keyword=search_query,\n",
        "         radius=distance,\n",
        "         page_token=next_page_token\n",
        "      )   \n",
        "      business_list.extend(response.get('results'))\n",
        "      next_page_token = response.get('next_page_token')\n",
        "\n",
        "  df = pd.DataFrame(business_list)\n",
        "  df['url'] = 'https://www.google.com/maps/place/?q=place_id:' + df['place_id']\n",
        "\n",
        "  #project dataframe down to column of the names of other supermarkets and convert it to a np array\n",
        "  df_names = df['name'].values\n",
        "\n",
        "  #remove names after the store, e.g. Aldi Nord --> remove 'Nord'\n",
        "  singular_store_names = []\n",
        "  for e in df_names:\n",
        "    str_arr = e.split()\n",
        "    singular_store_names.append(str_arr[0])\n",
        "  \n",
        "  #transform to set and back to remove duplicates\n",
        "  nn_stores = list(set(singular_store_names))\n",
        "\n",
        "  #remove original query / supermarket from array\n",
        "  for e in nn_stores:\n",
        "    if e.lower() == search_string.lower():\n",
        "      nn_stores.remove(e)\n",
        "\n",
        "  #now store only the supermarkets that are among the top-k ones based on the timeline\n",
        "  final_popular_markets = []\n",
        "  popularmarkets = timelinedict.keys()\n",
        "  for e in nn_stores:\n",
        "    for f in popularmarkets:\n",
        "      if e.lower() == f.lower():\n",
        "        final_popular_markets.append(e)\n",
        "\n",
        "\n",
        "  return final_popular_markets\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "aldilat = 54.3541912\n",
        "aldilng = 10.1050172\n",
        "aldinndf = getNearbySupermarkets(aldilat, aldilng)\n",
        "print(aldinndf)\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "routine goes through all supermarkets locations (keys) of a particular brand and computes per supermarkt an array of in-viccinity supermarkets that are based on the personal timeline top-k visited (value)\n",
        "'''\n",
        "def getAllNearestSupermarketsPerSupermarktX(querydict):\n",
        "  for key in querydict.keys():\n",
        "    lat, lng, dist, dur, pop = querydict[key]\n",
        "    popnnmarkets = getNearbySupermarkets(lat, lng)\n",
        "    querydict[key].append(popnnmarkets)\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Routine computes the utility score based on the afore collected information\n",
        "following things need to be weighted/are terms of the score:\n",
        "(1) the number of other supermarkets in the neighborhood of radius = eps\n",
        "(2) per supermarket in neighborhood the relative frequency e.g. 10x lidl / 91 supermarkt visits of the top-k\n",
        "(3) per supermarket the number of days (until now) since last visit\n",
        "\n",
        "how to incorporate these three facators?\n",
        "invert (^-1) to get a 'utility distance' / meaning that the lower the better...?\n",
        "\n",
        "Example:\n",
        "query: aldi\n",
        "in total 2 other supermarkets in radius of 1km:\n",
        "* rewe; overall 45 times visited, last visit 20 days ago\n",
        "* edeka; overall 22 times visited, last visit 1 day ago\n",
        "'''\n",
        "\n",
        "'''\n",
        "routine to compute the utility score\n",
        "call this function with a check in if-clause if viccinityarray is not zero. if it is, set score to zero since there is no 'utility' at all for that query supermarket\n",
        "'''\n",
        "\n",
        "def computeUtilityPerQueryLocation(viccinityarray):\n",
        "  #preliminary: compute total number of visits of top-k supermarkets\n",
        "  freq_totalvisits = 0\n",
        "  for supermarket in timelinedict:\n",
        "    freq_totalvisits = freq_totalvisits + len(timelinedict[supermarket])\n",
        "\n",
        "\n",
        "\n",
        "  #first term: compute ratio of number of top-k popular supermarkets in viccinity of a query supermarket to the total number (top-k) supermarkets\n",
        "  #+1 is since we account for the query supermarket contributing to the utility of a place\n",
        "  term1_topkamount = float(len(viccinityarray)+1) / float(len(timelinedict.keys()))\n",
        "  \n",
        "\n",
        "\n",
        "  #second term: compute sum over relations of frequencies per top-k supermarket occuring in viccinity of a query supermarket\n",
        "  term2_relationsfreq = 0\n",
        "  for supermarket in viccinityarray:\n",
        "    #to match supermarket name to the key of timelinedict\n",
        "    supermarketcaseopt = ''\n",
        "    for key in timelinedict.keys():\n",
        "      if supermarket.lower() == key.lower():\n",
        "        supermarketcaseopt = key\n",
        "\n",
        "    freq_supermarket = len(timelinedict[supermarketcaseopt])\n",
        "    term2_relationsfreq = term2_relationsfreq + (float(freq_supermarket) / float(freq_totalvisits))\n",
        "  #add the own query supermarket to the term\n",
        "  term2_relationsfreq = term2_relationsfreq + (float(len(timelinedict[search_string])) / float(freq_totalvisits))\n",
        "  \n",
        "\n",
        "  #third term: The sum over the inverse of number of days since last visited per supermarket in the viccinity of the query supermarket\n",
        "  term3_dayssinceratio = 0\n",
        "  for supermarket in viccinityarray:\n",
        "    #to match supermarket name to the key of timelinedict\n",
        "    supermarketcaseopt = ''\n",
        "    for key in timelinedict.keys():\n",
        "      if supermarket.lower() == key.lower():\n",
        "        supermarketcaseopt = key\n",
        "    \n",
        "\n",
        "    #get latest date since last visited a particular supermarket 'type'\n",
        "    lasttime = sorted(timelinedict[supermarketcaseopt])[-1]\n",
        "    #get number of days between last time visited and today (current day)\n",
        "    currtime_raw = datetime.datetime.now()\n",
        "    #truncate currtime_raw by removing time\n",
        "    currtime = datetime.date(currtime_raw.year, currtime_raw.month, currtime_raw.day)\n",
        "    deltadays = (currtime - lasttime).days\n",
        "    term3_dayssinceratio = term3_dayssinceratio + (float(1)/float(deltadays))\n",
        "\n",
        "  utilityscore = term1_topkamount + term2_relationsfreq + term3_dayssinceratio\n",
        "  #inverted score, because we want to have the lower values the better, since we also aim for lowest traffic time and lowest distance\n",
        "  #facilitates later on the computation of the pareto front\n",
        "  inverted_score = len(timelinedict.keys())+2 - utilityscore\n",
        "  return inverted_score\n"
      ],
      "metadata": {
        "id": "_CtXkF3N79dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "routine takes the dictionary with place_id as key and appends the utility of that location: [lat, lng, dist, dur, poptimes, history, util]\n",
        "'''\n",
        "\n",
        "def append_utility_to_querydict(querydict):\n",
        "  for key in querydict.keys():\n",
        "    neighborhood_list = querydict[key][5]\n",
        "    if neighborhood_list:\n",
        "      util = computeUtilityPerQueryLocation(neighborhood_list)\n",
        "      querydict[key].append(util)\n",
        "    else:\n",
        "      #for the case that no other supermarket is in viccinity of query supermarket --> penalize with highest score possible\n",
        "      maxscore = len(timelinedict.keys())+2\n",
        "      querydict[key].append(maxscore)"
      ],
      "metadata": {
        "id": "XUeDJJUU70rc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#computation of lat,lng coors, shortest distance, minimum traffic duration, relative populartimes\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "startcoor = (lat, lng)\n",
        "\n",
        "append_shortest_distances_to_querydict(extracted_dict, startcoor)\n",
        "\n",
        "append_minduration_path_to_querydict(extracted_dict, startcoor)\n",
        "\n",
        "import datetime\n",
        "\n",
        "append_relpopularity_to_querydict(extracted_dict)\n",
        "\n",
        "\n",
        "alljsonfilesarray = glob.glob('INSERT PATH TO GOOGLE TIMELINE DATA HERE')\n",
        "\n",
        "for jsonfile in alljsonfilesarray:\n",
        "  populateTimelineDict(jsonfile)   \n",
        "\n",
        "pruneTimelineDict(timelinedict, 5)\n",
        "\n",
        "getAllNearestSupermarketsPerSupermarktX(extracted_dict)\n",
        "\n",
        "append_utility_to_querydict(extracted_dict)\n",
        "for key in extracted_dict:\n",
        "  print('key: ', key, ' val: ',extracted_dict[key])\n",
        "\n",
        "print(extracted_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niTyKHuhaX_3",
        "outputId": "bd326a1e-04ca-44bc-be00-0f20ec209621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "key:  ChIJ4-7amiFUskcRx-eGSnsU11k  val:  [54.3002176, 10.0878471, 6.612, 14.85, 0.8627450980392157, ['Lidl', 'Rewe', 'EDEKA', 'REWE'], 5.750335481082384]\n",
            "key:  ChIJDZ-XVWhWskcR2dwtbNtK8O8  val:  [54.3293103, 10.1336699, 2.938, 7.316666666666666, 0.7945205479452054, ['EDEKA', 'Lidl', 'REWE'], 6.366812753809658]\n",
            "key:  ChIJsQVmc-9WskcRS3BV6SyHPoc  val:  [54.3009059, 10.1422826, 6.389, 16.416666666666668, 1.94, ['EDEKA', 'Lidl', 'REWE'], 6.366812753809658]\n",
            "key:  ChIJs9hxzan4skcRqcd-I9tLT34  val:  [54.36001830000001, 10.1336367, 5.267, 7.533333333333333, 0.703125, ['REWE'], 7.0189393939393945]\n",
            "key:  ChIJv1foXo1WskcRc46YWdst7G8  val:  [54.30565739999999, 10.126084, 4.824, 12.883333333333333, 0.7910447761194029, ['Rewe', 'EDEKA', 'Lidl', 'REWE'], 5.750335481082384]\n",
            "key:  ChIJr3BHgGxWskcRTMhzuUNuFCs  val:  [54.33495600000001, 10.1320073, 2.985, 7.733333333333333, 1.0158730158730158, ['EDEKA', 'Lidl', 'REWE'], 6.366812753809658]\n",
            "key:  ChIJbdJh06xVskcRmTMLU8MGjxw  val:  [54.3237325, 10.054179, 5.291, 10.35, 0.8857142857142857, ['Rewe', 'Kaufland', 'REWE'], 6.183712121212121]\n",
            "key:  ChIJzZROoMdXskcRE_QE-o8f6b4  val:  [54.3345708, 10.1901217, 11.089, 23.466666666666665, 1.0, ['Lidl', 'EDEKA', 'REWE'], 6.366812753809658]\n",
            "key:  ChIJXSeN6KVXskcRFJGcvDemrG4  val:  [54.3175444, 10.1830397, 9.714, 22.466666666666665, 1.21875, ['Lidl', 'REWE'], 6.645164884135473]\n",
            "key:  ChIJD_5lsftVskcRXxLeRcwxGE4  val:  [54.3541912, 10.1050172, 2.393, 5.566666666666666, 0.8529411764705882, ['EDEKA', 'REWE'], 6.7405872636135795]\n",
            "key:  ChIJO09VeTUAs0cRkIe4HZECZiY  val:  [54.41428999999999, 9.9833521, 15.152, 12.983333333333333, 0.34328358208955223, ['Lidl', 'EDEKA', 'REWE'], 6.366812753809658]\n",
            "key:  ChIJ464ABndWskcRPJCnE1Dik1g  val:  [54.3303344, 10.1112091, 1.829, 5.316666666666666, 0.5555555555555556, ['EDEKA', 'Lidl', 'REWE'], 6.366812753809658]\n",
            "key:  ChIJLaOVCZlWskcRB0eVEk7UpsI  val:  [54.2992614, 10.1049832, 6.036, 15.666666666666666, 0.8382352941176471, ['Rewe', 'EDEKA', 'Lidl', 'REWE'], 5.750335481082384]\n",
            "key:  ChIJBTcEixBXskcRnRE7xmZfW_E  val:  [54.2978171, 10.1737386, 8.644, 18.083333333333332, 0.35714285714285715, ['REWE', 'Lidl'], 6.645164884135473]\n",
            "key:  ChIJ_____1hWskcR1zT-wJoIK18  val:  [54.31439839999999, 10.1467048, 6.03, 18.333333333333332, 1.6842105263157894, ['EDEKA', 'Lidl', 'REWE'], 6.366812753809658]\n",
            "key:  ChIJb9_69MVWskcRuM_DnXLLQ5c  val:  [54.2823898, 10.1321279, 8.27, 16.883333333333333, 0.5760869565217391, ['EDEKA'], 7.357064536340852]\n",
            "key:  ChIJtRZoiv9WskcR7ohQ-eBS7T0  val:  [54.3125073, 10.159109, 7.563, 18.266666666666666, 0.7076923076923077, ['EDEKA', 'Lidl', 'REWE'], 6.366812753809658]\n",
            "key:  ChIJNwH-4NP-skcRvBKgDuhimL4  val:  [54.4102781, 10.1301003, 10.924, 11.033333333333333, 0.5625, ['EDEKA'], 7.357064536340852]\n",
            "key:  ChIJGVJsHsn4skcRTahcUbZPD7g  val:  [54.3846564, 10.1388724, 8.173, 8.883333333333333, 0.2033898305084746, ['Rewe', 'EDEKA', 'REWE'], 6.124109990886307]\n",
            "key:  ChIJU2qUhBX4skcRDZJQoU4KCUQ  val:  [54.3766901, 10.221551, 17.605, 27.916666666666668, 0.49333333333333335, ['EDEKA', 'REWE'], 6.7405872636135795]\n",
            "key:  ChIJX5MyNb5XskcRjdhvakFidJs  val:  [54.3290837, 10.1984425, 10.968, 22.766666666666666, inf, ['Lidl', 'EDEKA', 'REWE'], 6.366812753809658]\n",
            "key:  ChIJARO96YFWskcR2Js37kmDSDk  val:  [54.3118413, 10.0985562, 4.303, 6.0, 0.4782608695652174, ['Rewe', 'EDEKA', 'Lidl', 'REWE'], 5.750335481082384]\n",
            "key:  ChIJ25acP_JVskcR66VeNl7Dki0  val:  [54.3532932, 10.0922142, 2.546, 6.133333333333334, 0.4, ['EDEKA', 'REWE'], 6.7405872636135795]\n",
            "key:  ChIJf27rluP4skcRDmkmbVOug6w  val:  [54.3960602, 10.1731945, 10.957, 13.7, 1.0377358490566038, ['Lidl', 'Rewe', 'REWE'], 6.0286876114082]\n",
            "key:  ChIJwQCXp-BZskcRfl5Hmm--c5c  val:  [54.28448460000001, 10.221673, 13.027, 21.683333333333334, 0.8484848484848485, ['Lidl', 'REWE'], 6.645164884135473]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#project down to columns containing place_id and vicinity for label information in the plot\n",
        "df_projected = df[['place_id', 'vicinity']]\n",
        "\n",
        "df_projected.head()\n",
        "\n",
        "df_dict = df_projected.set_index('place_id').T.to_dict('list')\n",
        "\n",
        "df_dict"
      ],
      "metadata": {
        "id": "d9oJUXlwfKIC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}